{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: Precision & Recall\n",
    "\n",
    "Using the evaluation metrics we have learned, we are going to compare how well some different types of classifiers perform on different evaluation metrics.\n",
    "\n",
    "We are going to use a dataset of written numbers which we can import from sklearn. Run the code below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "mnist = fetch_openml('mnist_784')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now take a look at the shapes of the X and y matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's pick one entry and see what number is written. Use indexing to pick the 35th digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  29., 141., 198., 255., 198.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,  86., 141., 198., 255., 255., 255., 255.,\n",
       "       170.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29., 141., 226., 255.,\n",
       "       255., 255., 255., 198.,  86.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0., 170., 255., 255., 170.,  86.,  86.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 141., 226., 170.,  57.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  86., 255., 198.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 198., 255., 141.,  86.,\n",
       "        57.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0., 170., 255., 198., 114., 226., 170.,  29.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  57., 198., 255., 114.,  29.,   0.,\n",
       "       141., 255.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       114., 255., 114.,   0.,   0.,   0., 141., 255.,  29.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  29.,   0.,   0.,   0.,\n",
       "         0., 226., 255.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0., 114., 255., 141.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  86.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       114., 226., 226.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 255., 198.,\n",
       "        86.,   0.,   0.,   0., 141., 255., 255., 170.,  29.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0., 226., 255., 226., 170., 226., 255., 255.,\n",
       "       198.,  29.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  86.,\n",
       "       198., 255., 255., 170., 141.,  57.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "X[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Use the *reshape(28,28)* method and *plt.imshow()* function with the parameters *cmap = matplotlib.cm.binary* and *interpolation=\"nearest\"* to make a plot of the number. Be sure to import matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2314a226508>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "number = X[20]\n",
    "number_image = number.reshape(28, 28)\n",
    "plt.imshow(number_image, cmap = plt.cm.binary, interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use indexing to see if what the plot shows matches with the outcome of the 35th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2314a27fa88>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# your code here\n",
    "number = X[35]\n",
    "number_image = number.reshape(28, 28)\n",
    "plt.imshow(number_image, cmap = plt.cm.binary, interpolation = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets break into a test train split to run a classification. Instead of using sklearn, use indexing to select the first 60000 entries for the training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "x_train = X[:60000]\n",
    "x_test = X[60000:]\n",
    "y_train = y[:60000]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to make a two-class classifier, so lets restrict to just one number, for example 5s. Do this by defining a new y training and y testing sets for just the number 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y5_train = np.where(y_train == '5', 1, 0)\n",
    "y5_test = np.where(y_test == '5', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets train a logistic regression to predict if a number is a 5 or not. Remember to use the 'just 5s' target train array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gareth\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod5 = LogisticRegression().fit(x_train, y5_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the classifier predict correctly the 35th digit we picked before?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "y_pred_5 = mod5.predict(x_train)\n",
    "print(y_pred[35])\n",
    "print(y[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = True, 0 = False. Therefore, it is a correct prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 36000th value is a 9. Check if it was correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(y_pred[36000])\n",
    "print(y[36000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is trained to detect a 5, so it will not detect a 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make some comparisons, we are going to make a very dumb classifier, that never predicts 5s. Build the classifier with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumb classifier\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        return np.zeros((len(X), 1))[:, 0]\n",
    "\n",
    "never_5_clf = Never5Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now lets fit and predict on the testing set using our dumb classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "never_5_clf.fit(x_train)\n",
    "never_5_predict = never_5_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's compare this to the Logistic Regression. Examine the confusion matrix, precision, recall, and f1_scores for each. What is the probability cutoff you are using to decide the classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.9108 0.    ]\n",
      "recall: [1. 0.]\n",
      "fscore: [0.95331798 0.        ]\n",
      "confusion matrix: [9108  892]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gareth\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "\n",
    "precision, recall, fscore, confusion_matrix = score(y5_test, never_5_predict)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('confusion matrix: {}'.format(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mod5.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.98398867 0.90964591]\n",
      "recall: [0.99187527 0.83520179]\n",
      "fscore: [0.98791623 0.87083577]\n",
      "confusion matrix: [9108  892]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, confusion_matrix = score(y5_test, y_pred)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('confusion matrix: {}'.format(confusion_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the differences you see? Without knowing what each model is, what can these metrics tell you about how well each works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The precision is better with the Logistic Regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's examine the roc_curve for each. Use the roc_curve method from sklearn.metrics to help plot the curve for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [10000, 60000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-142-7e02c5da0dc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my5_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \"\"\"\n\u001b[0;32m    770\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 771\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    772\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 212\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [10000, 60000]"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn import metrics \n",
    "\n",
    "metrics.roc_curve(y5_test, y_pred_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now find the roc_auc_score for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does this metric tell you? Which classifier works better with this metric in mind?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
